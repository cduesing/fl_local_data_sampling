{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "h9hU9VZE8ByX",
   "metadata": {
    "id": "h9hU9VZE8ByX"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ce3f4b-63b2-4613-b614-9400a6543ba4",
   "metadata": {
    "id": "e2ce3f4b-63b2-4613-b614-9400a6543ba4"
   },
   "outputs": [],
   "source": [
    "import strategies\n",
    "import load_data\n",
    "import baselines\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statistics\n",
    "import warnings\n",
    "import pickle\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from collections import Counter\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7qJ2eZ-u8Eco",
   "metadata": {
    "id": "7qJ2eZ-u8Eco"
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c5dc30-59b5-4068-8821-dab06754776c",
   "metadata": {
    "id": "b2c5dc30-59b5-4068-8821-dab06754776c"
   },
   "outputs": [],
   "source": [
    "# Data Features\n",
    "dataset_name = \"MNIST\"\n",
    "\n",
    "# Data Distribution\n",
    "attribute_skew = None #\"noise\"\n",
    "label_or_quantity_skew = \"label_distribution\"\n",
    "label_alpha = 2\n",
    "label_n = None\n",
    "attribute_alpha = None\n",
    "num_clients = 100\n",
    "purity = None\n",
    "\n",
    "# Analysis Parameters\n",
    "num_quantiles = 4\n",
    "\n",
    "# Lerning Parametes\n",
    "num_local_epochs = 3\n",
    "local_multiplier = 0\n",
    "num_rounds = 200\n",
    "\n",
    "# Learning Strategy\n",
    "strategy_name = \"FedAvg\"\n",
    "model_name = \"auto\"\n",
    "bert_pretrained_model = None\n",
    "stepsize = 1.2\n",
    "weighted = True\n",
    "reset_per_round = False\n",
    "\n",
    "# Static Parameters\n",
    "batch_size= 64\n",
    "device = \"cuda\"\n",
    "test_set_fraction = 0.2\n",
    "shared_set_fraction = 0\n",
    "\n",
    "# Logging\n",
    "log_per_round = False\n",
    "log_file = None\n",
    "averaging = \"weighted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2945293c-6ace-43e6-90c1-c8fe0130c982",
   "metadata": {
    "id": "2945293c-6ace-43e6-90c1-c8fe0130c982"
   },
   "outputs": [],
   "source": [
    "default_config = {\n",
    "    \"strategy_name\": strategy_name,\n",
    "    \"model_name\": model_name,\n",
    "    \"bert_pretrained_model\":bert_pretrained_model,\n",
    "    \"dataset_name\": dataset_name,\n",
    "\n",
    "    \"num_clients\":num_clients,\n",
    "    \"batch_size\":batch_size,\n",
    "\n",
    "    \"weighted\":weighted,\n",
    "    \"reset_per_round\":reset_per_round,\n",
    "\n",
    "    \"device\":device,\n",
    "    \"stepsize\":stepsize,\n",
    "    \"rounds\": num_rounds,\n",
    "    \"local_epochs\": num_local_epochs,\n",
    "    \"local_multiplier\": local_multiplier,\n",
    "\n",
    "    \"attribute_skew\": attribute_skew,\n",
    "    \"label_skew\": label_or_quantity_skew,\n",
    "    \"label_alpha\": label_alpha,\n",
    "    \"label_n\": label_n,\n",
    "    \"attribute_alpha\": attribute_alpha,\n",
    "    \"purity\": purity,\n",
    "\n",
    "    \"num_quantiles\": num_quantiles,\n",
    "\n",
    "    \"test_set_fraction\": test_set_fraction,\n",
    "    \"shared_set_fraction\": shared_set_fraction,\n",
    "\n",
    "    \"evaluation_averaging\": averaging,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XF-rd6zz8Gy3",
   "metadata": {
    "id": "XF-rd6zz8Gy3"
   },
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emeYfEWS8OgY",
   "metadata": {
    "id": "emeYfEWS8OgY"
   },
   "outputs": [],
   "source": [
    "def apply_sampling(mode, features, labels, X_test, y_test, num_classes, mean_size, sampling_strategy=\"auto\"):\n",
    "\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    feature_shape = list(features.shape)\n",
    "    X_test = np.array(X_test).reshape(len(X_test),-1)\n",
    "\n",
    "    counter_dict = dict(Counter(labels))\n",
    "    cnts = [a for _,a in Counter(labels).items()]\n",
    "    if (len(list(set(labels))) < num_classes or min(cnts) < 6) and mode is not None:\n",
    "        return None, None, \"excluded\"\n",
    "    if mode == \"constrained\":\n",
    "        return features, labels, \"constrained\"\n",
    "    elif mode == \"undersampling\":\n",
    "        if sampling_strategy != \"auto\" and num_classes > 2:\n",
    "            num_samples = int(max(cnts)*sampling_strategy)\n",
    "            sampler = {x:min(counter_dict[x], num_samples) for x in range(num_classes)}\n",
    "        else:\n",
    "            sampler = sampling_strategy\n",
    "        undersample = RandomUnderSampler(sampling_strategy=sampler)\n",
    "        if sampling_strategy != \"auto\" and sampling_strategy <= min(cnts)/max(cnts):\n",
    "            return features, labels, \"undersampling\"\n",
    "        X,y = undersample.fit_resample(features.reshape(feature_shape[0], -1), labels)\n",
    "        feature_shape[0] = -1\n",
    "        return X.reshape(feature_shape), y, \"undersampling\"\n",
    "    elif mode == \"oversampling\":\n",
    "        if sampling_strategy != \"auto\" and num_classes > 2:\n",
    "            num_samples = int(max(cnts)*sampling_strategy)\n",
    "            sampler = {x:max(counter_dict[x], num_samples) for x in range(num_classes)}\n",
    "        else:\n",
    "            sampler = sampling_strategy\n",
    "        oversample = SMOTE(sampling_strategy=sampler)\n",
    "        if sampling_strategy != \"auto\" and sampling_strategy <= min(cnts)/max(cnts):\n",
    "            return features, labels, \"oversampling\"\n",
    "        X,y = oversample.fit_resample(features.reshape(feature_shape[0], -1), labels)\n",
    "        feature_shape[0] = -1\n",
    "        return X.reshape(feature_shape), y, \"oversampling\"\n",
    "    elif mode == \"hybrid\":\n",
    "        if sampling_strategy != \"auto\" and num_classes > 2:\n",
    "            num_samples = int(max(cnts)*sampling_strategy)\n",
    "            sampler = {x:max(counter_dict[x], num_samples) for x in range(num_classes)}\n",
    "        else:\n",
    "            sampler = sampling_strategy\n",
    "        smt = SMOTETomek(sampling_strategy=sampler)\n",
    "        if sampling_strategy != \"auto\" and sampling_strategy <= min(cnts)/max(cnts):\n",
    "            return features, labels, \"hybridsampling\"\n",
    "        X,y = smt.fit_resample(features.reshape(feature_shape[0], -1), labels)\n",
    "        feature_shape[0] = -1\n",
    "        return X.reshape(feature_shape), y, \"hybridsampling\"\n",
    "    elif mode == \"dynamic\":\n",
    "        if len(labels) > mean_size:\n",
    "            undersample = RandomUnderSampler(sampling_strategy=sampling_strategy)\n",
    "            X,y = undersample.fit_resample(features.reshape(feature_shape[0], -1), labels)\n",
    "            feature_shape[0] = -1\n",
    "            return X.reshape(feature_shape), y, \"undersampling\"\n",
    "        else:\n",
    "            oversample = SMOTE(sampling_strategy=sampling_strategy)\n",
    "            X,y = oversample.fit_resample(features.reshape(feature_shape[0], -1), labels)\n",
    "            feature_shape[0] = -1\n",
    "            return X.reshape(feature_shape), y, \"oversampling\"\n",
    "    elif mode == \"optimized\":\n",
    "        undersample = RandomUnderSampler(sampling_strategy=sampling_strategy)\n",
    "        X_train_us, y_train_us = undersample.fit_resample(features.reshape(feature_shape[0], -1), labels)\n",
    "        clf = RandomForestClassifier(n_estimators=150, max_depth=10, random_state=0)\n",
    "        clf.fit(X_train_us, y_train_us)\n",
    "        preds = clf.predict(X_test)\n",
    "        acc_us = accuracy_score(y_test, preds)\n",
    "\n",
    "        oversample = SMOTE(sampling_strategy=sampling_strategy)\n",
    "        X_train_os, y_train_os = oversample.fit_resample(features.reshape(feature_shape[0], -1), labels)\n",
    "        clf = RandomForestClassifier(n_estimators=150, max_depth=10, random_state=0)\n",
    "        clf.fit(X_train_os, y_train_os)\n",
    "        preds = clf.predict(X_test)\n",
    "        acc_os = accuracy_score(y_test, preds)\n",
    "\n",
    "        smt = SMOTETomek(sampling_strategy=sampling_strategy)\n",
    "        X_train_hs, y_train_hs = smt.fit_resample(features.reshape(feature_shape[0], -1), labels)\n",
    "        clf = RandomForestClassifier(n_estimators=150, max_depth=10, random_state=0)\n",
    "        clf.fit(X_train_hs, y_train_hs)\n",
    "        preds = clf.predict(X_test)\n",
    "        acc_hs = accuracy_score(y_test, preds)\n",
    "\n",
    "        feature_shape[0] = -1\n",
    "        if acc_us >= acc_os and acc_us >= acc_hs:\n",
    "            return X_train_us.reshape(feature_shape), y_train_us, \"undersampling\"\n",
    "        elif acc_os >= acc_os and acc_os >= acc_hs:\n",
    "            return X_train_os.reshape(feature_shape), y_train_os, \"oversampling\"\n",
    "        elif acc_hs >= acc_us and acc_hs >= acc_os:\n",
    "            return X_train_os.reshape(feature_shape), y_train_os, \"hybridsampling\"\n",
    "    #else\n",
    "    return features, labels, \"none\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc0414e-6b25-42e6-95b1-55558f5f5ed6",
   "metadata": {},
   "source": [
    "### Samples per Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Y7oMbHLypK5L",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2104805,
     "status": "ok",
     "timestamp": 1697813792173,
     "user": {
      "displayName": "Christoph Düsing",
      "userId": "09468983824045389594"
     },
     "user_tz": -120
    },
    "id": "Y7oMbHLypK5L",
    "outputId": "4461564c-f94f-4612-9949-f508bcd347ab"
   },
   "outputs": [],
   "source": [
    "all_central_metrics = []\n",
    "\n",
    "samplings = [None, \"constrained\", \"oversampling\", \"undersampling\", \"dynamic\", \"hybrid\", \"optimized\"]\n",
    "if default_config[\"dataset_name\"] == \"hand\":\n",
    "    maxs = [650, 600, 500,400,300,200,100]\n",
    "elif default_config[\"dataset_name\"] == \"diabetes_insulin\":\n",
    "    maxs = [1000,750,500,350,200,150,100]\n",
    "elif default_config[\"dataset_name\"] == \"MNIST\":\n",
    "    maxs = [480,450,400,300,200,150,100]\n",
    "else:\n",
    "    maxs = [4000,3000,2000,1000,500,200,100]\n",
    "\n",
    "default_config = load_data.load_raw_data(default_config)\n",
    "default_config = load_data.distribute_skewed_data(default_config)\n",
    "\n",
    "for max in maxs:\n",
    "    config = deepcopy(default_config)\n",
    "\n",
    "    for key in config[\"clients_feature_dict\"]:\n",
    "          indices = random.sample(range(0, len(config[\"clients_feature_dict\"][key])), min(max, len(config[\"clients_feature_dict\"][key])))\n",
    "          config[\"clients_feature_dict\"][key]  = np.array(config[\"clients_feature_dict\"][key])[indices].tolist()\n",
    "          config[\"clients_label_dict\"][key]  = np.array(config[\"clients_label_dict\"][key])[indices].tolist()\n",
    "    print(\"Max client size\", max)\n",
    "\n",
    "    m = statistics.mean([len(x) for x in config[\"clients_label_dict\"].values()])\n",
    "\n",
    "    for sampling in samplings:\n",
    "      print(\"Sampling:\", sampling)\n",
    "      local_config = deepcopy(config)\n",
    "\n",
    "      feature_dict = local_config[\"clients_feature_dict\"]\n",
    "      label_dict = local_config[\"clients_label_dict\"]\n",
    "      excluded=[]\n",
    "      modes = []\n",
    "      for key in feature_dict:\n",
    "          sampled_features, sampled_labels, mode = apply_sampling(sampling, feature_dict[key], label_dict[key], local_config[\"X_train\"], local_config[\"y_train\"], local_config[\"num_classes\"], m)\n",
    "          modes.append(mode)\n",
    "          feature_dict[key] = sampled_features\n",
    "          label_dict[key] = sampled_labels\n",
    "          if sampled_features is None:\n",
    "              excluded.append(key)\n",
    "      print(\"Modes\", Counter(modes))\n",
    "      local_config[\"clients_feature_dict\"] = feature_dict\n",
    "      local_config[\"clients_label_dict\"] = label_dict\n",
    "\n",
    "      excluded.reverse()\n",
    "      for i in excluded:\n",
    "          max_idx = len(local_config[\"clients_feature_dict\"])-1\n",
    "          local_config[\"clients_feature_dict\"][i] = local_config[\"clients_feature_dict\"][max_idx]\n",
    "          del local_config[\"clients_feature_dict\"][max_idx]\n",
    "          local_config[\"clients_label_dict\"][i] = local_config[\"clients_label_dict\"][max_idx]\n",
    "          del local_config[\"clients_label_dict\"][max_idx]\n",
    "      local_config[\"num_clients\"] = local_config[\"num_clients\"] - len(excluded)\n",
    "\n",
    "      learning_strategy = strategies.get_strategy_by_name(local_config)\n",
    "\n",
    "      federated_model, federated_f1s = learning_strategy.run(local_config, filename=log_file, log_per_round=log_per_round, return_f1s=True)\n",
    "      _, _, _, central_metrics = baselines.run_local_baselines(local_config, central_model=federated_model, filename=log_file)\n",
    "\n",
    "      all_central_metrics.append(central_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79d01c0-44cd-4595-9f45-66a8580122d3",
   "metadata": {},
   "source": [
    "### Cohort Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XkGJFG8vpat3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 730017,
     "status": "ok",
     "timestamp": 1697814522187,
     "user": {
      "displayName": "Christoph Düsing",
      "userId": "09468983824045389594"
     },
     "user_tz": -120
    },
    "id": "XkGJFG8vpat3",
    "outputId": "f75e33b7-035c-4bb9-a419-ae34688409f6"
   },
   "outputs": [],
   "source": [
    "all_central_metrics = []\n",
    "\n",
    "samplings = [None, \"constrained\", \"oversampling\", \"undersampling\", \"dynamic\", \"hybrid\", \"optimized\"]\n",
    "removes = [10,20,30,40,50,60,70,80,90,91,92,93,94,95]\n",
    "\n",
    "default_config = load_data.load_raw_data(default_config)\n",
    "default_config = load_data.distribute_skewed_data(default_config)\n",
    "\n",
    "for remove in removes:\n",
    "    config = deepcopy(default_config)\n",
    "\n",
    "    remove_idx = list(sorted(random.sample(range(0, config[\"num_clients\"]), remove)))\n",
    "    remove_idx.reverse()\n",
    "\n",
    "    for i in remove_idx:\n",
    "          max_idx = len(config[\"clients_feature_dict\"])-1\n",
    "          config[\"clients_feature_dict\"][i] = config[\"clients_feature_dict\"][max_idx]\n",
    "          del config[\"clients_feature_dict\"][max_idx]\n",
    "          config[\"clients_label_dict\"][i] = config[\"clients_label_dict\"][max_idx]\n",
    "          del config[\"clients_label_dict\"][max_idx]\n",
    "    config[\"num_clients\"] = config[\"num_clients\"] - remove\n",
    "\n",
    "    print(\"Cohort size\", config[\"num_clients\"])\n",
    "\n",
    "    m = statistics.mean([len(x) for x in config[\"clients_label_dict\"].values()])\n",
    "\n",
    "    for sampling in samplings:\n",
    "      print(\"Sampling:\", sampling)\n",
    "      local_config = deepcopy(config)\n",
    "\n",
    "      feature_dict = local_config[\"clients_feature_dict\"]\n",
    "      label_dict = local_config[\"clients_label_dict\"]\n",
    "      excluded=[]\n",
    "      modes = []\n",
    "      for key in feature_dict:\n",
    "          sampled_features, sampled_labels, mode = apply_sampling(sampling, feature_dict[key], label_dict[key], local_config[\"X_train\"], local_config[\"y_train\"], local_config[\"num_classes\"], m)\n",
    "          modes.append(mode)\n",
    "          feature_dict[key] = sampled_features\n",
    "          label_dict[key] = sampled_labels\n",
    "          if sampled_features is None:\n",
    "              excluded.append(key)\n",
    "      print(\"Modes\", Counter(modes))\n",
    "      local_config[\"clients_feature_dict\"] = feature_dict\n",
    "      local_config[\"clients_label_dict\"] = label_dict\n",
    "\n",
    "      excluded.reverse()\n",
    "      for i in excluded:\n",
    "          max_idx = len(local_config[\"clients_feature_dict\"])-1\n",
    "          local_config[\"clients_feature_dict\"][i] = local_config[\"clients_feature_dict\"][max_idx]\n",
    "          del local_config[\"clients_feature_dict\"][max_idx]\n",
    "          local_config[\"clients_label_dict\"][i] = local_config[\"clients_label_dict\"][max_idx]\n",
    "          del local_config[\"clients_label_dict\"][max_idx]\n",
    "      local_config[\"num_clients\"] = local_config[\"num_clients\"] - len(excluded)\n",
    "\n",
    "      learning_strategy = strategies.get_strategy_by_name(local_config)\n",
    "\n",
    "      federated_model, federated_f1s = learning_strategy.run(local_config, filename=log_file, log_per_round=log_per_round, return_f1s=True)\n",
    "      _, _, _, central_metrics = baselines.run_local_baselines(local_config, central_model=federated_model, filename=log_file)\n",
    "\n",
    "      all_central_metrics.append(central_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62130528-3161-476a-8d54-9445476ab8cb",
   "metadata": {},
   "source": [
    "### Data Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2PKxHNqTJcWG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3734009,
     "status": "ok",
     "timestamp": 1697818442747,
     "user": {
      "displayName": "Christoph Düsing",
      "userId": "09468983824045389594"
     },
     "user_tz": -120
    },
    "id": "2PKxHNqTJcWG",
    "outputId": "78d36ff7-adc7-4b1c-ac02-ba39751cab12"
   },
   "outputs": [],
   "source": [
    "all_central_metrics = []\n",
    "\n",
    "samplings = [None, \"constrained\", \"oversampling\", \"undersampling\", \"dynamic\", \"hybrid\", \"optimized\"]\n",
    "\n",
    "alphas = [100,50,20,10,5,2,1,0.5,0.2,0.1]\n",
    "\n",
    "for alpha in alphas:\n",
    "    default_config[\"label_alpha\"] = alpha\n",
    "    print(\"Alpha:\", alpha)\n",
    "\n",
    "    config = load_data.load_raw_data(default_config)\n",
    "    config = load_data.distribute_skewed_data(config)\n",
    "\n",
    "    m = statistics.mean([len(x) for x in config[\"clients_label_dict\"].values()])\n",
    "\n",
    "    for sampling in samplings:\n",
    "      print(\"Sampling:\", sampling)\n",
    "      local_config = deepcopy(config)\n",
    "\n",
    "      feature_dict = local_config[\"clients_feature_dict\"]\n",
    "      label_dict = local_config[\"clients_label_dict\"]\n",
    "      excluded=[]\n",
    "      modes = []\n",
    "      for key in feature_dict:\n",
    "          sampled_features, sampled_labels, mode = apply_sampling(sampling, feature_dict[key], label_dict[key], local_config[\"X_train\"], local_config[\"y_train\"], local_config[\"num_classes\"], m)\n",
    "          modes.append(mode)\n",
    "          feature_dict[key] = sampled_features\n",
    "          label_dict[key] = sampled_labels\n",
    "          if sampled_features is None:\n",
    "              excluded.append(key)\n",
    "      print(\"Modes\", Counter(modes))\n",
    "      local_config[\"clients_feature_dict\"] = feature_dict\n",
    "      local_config[\"clients_label_dict\"] = label_dict\n",
    "\n",
    "      excluded.reverse()\n",
    "      for i in excluded:\n",
    "          max_idx = len(local_config[\"clients_feature_dict\"])-1\n",
    "          local_config[\"clients_feature_dict\"][i] = local_config[\"clients_feature_dict\"][max_idx]\n",
    "          del local_config[\"clients_feature_dict\"][max_idx]\n",
    "          local_config[\"clients_label_dict\"][i] = local_config[\"clients_label_dict\"][max_idx]\n",
    "          del local_config[\"clients_label_dict\"][max_idx]\n",
    "      local_config[\"num_clients\"] = local_config[\"num_clients\"] - len(excluded)\n",
    "\n",
    "      learning_strategy = strategies.get_strategy_by_name(local_config)\n",
    "\n",
    "\n",
    "      federated_model, federated_f1s = learning_strategy.run(local_config, filename=log_file, log_per_round=log_per_round, return_f1s=True)\n",
    "      _, _, _, central_metrics = baselines.run_local_baselines(local_config, central_model=federated_model, filename=log_file)\n",
    "\n",
    "      all_central_metrics.append(central_metrics)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "m3ZgRl_jsBCe",
    "hDHwZSBANgkk",
    "eSCD7sdLNmzL"
   ],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
